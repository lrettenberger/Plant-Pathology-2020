{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1639 images belonging to 4 classes.\n",
      "Found 182 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "NEW_DATA_DIR = './data'\n",
    "TRAIN_DIR = NEW_DATA_DIR + '/Train'\n",
    "TEST_DIR = NEW_DATA_DIR + '/Test'\n",
    "VALID_DIR = NEW_DATA_DIR + '/Valid'\n",
    "test_size = 0.10\n",
    "\n",
    "import keras\n",
    "import cv2\n",
    "\n",
    "def blur(img):\n",
    "    rand_int = np.random.randint(11)\n",
    "    if rand_int <= 1:\n",
    "        blurred = (cv2.blur(img,(5,5)))\n",
    "        return blurred\n",
    "    if rand_int <= 3:\n",
    "        kernel = np.ones((6, 6), np.float32)/20\n",
    "        filtered = cv2.filter2D(img, -1, kernel)\n",
    "        return filtered\n",
    "    return img\n",
    "\n",
    "#image_size = (136, 204)\n",
    "image_size = (299, 299)\n",
    "batch_size = 10\n",
    "\n",
    "# Rescale all images by 1./255 and apply image augmentation\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=.1,\n",
    "    fill_mode='nearest',\n",
    "    shear_range=0.1,\n",
    "    rescale=1/255,\n",
    "    brightness_range=[0.5, 1.5],\n",
    "    preprocessing_function= blur)\n",
    "validation_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                TRAIN_DIR,\n",
    "                target_size=(image_size[0], image_size[1]),\n",
    "                batch_size=batch_size,\n",
    "                class_mode='categorical',\n",
    "                shuffle=True)\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "test_generator = validation_datagen.flow_from_directory(\n",
    "                TEST_DIR, # Source directory for the validation images\n",
    "                target_size=(image_size[0], image_size[1]),\n",
    "                batch_size=batch_size,\n",
    "                class_mode='categorical',\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import DenseNet121,DenseNet201\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.models import Sequential , Model\n",
    "from tensorflow.keras.layers import Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam , RMSprop \n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n",
    "\n",
    "img_size = 299\n",
    "\n",
    "def get_model(model_name) :\n",
    "    if model_name == 'MobileNet' :\n",
    "        base_model=MobileNet(weights='imagenet',include_top=False,input_shape=(img_size,img_size,3))\n",
    "    elif model_name == 'VGG16' : \n",
    "        base_model=vgg16.VGG16(weights='imagenet',include_top=False,input_shape=(img_size,img_size,3))\n",
    "    elif model_name == 'DenseNet' :\n",
    "        base_model = DenseNet121(weights='imagenet',include_top=False,input_shape=(img_size,img_size,3))\n",
    "    elif model_name == 'DenseNet201' :\n",
    "        base_model = DenseNet201(weights='imagenet',include_top=False,input_shape=(img_size,img_size,3))\n",
    "    elif model_name == 'Inception' :\n",
    "        base_model=InceptionV3(weights='imagenet',include_top=False,input_shape=(img_size,img_size,3))\n",
    "    elif model_name == 'ResNet' :\n",
    "        base_model = ResNet50(weights='imagenet',include_top=False,input_shape=(img_size,img_size,3))\n",
    "    x=base_model.output\n",
    "    x=GlobalAveragePooling2D()(x)\n",
    "    x=Dense(512,activation='relu')(x)\n",
    "    x=Dropout(0.3)(x)\n",
    "    x=Dense(256,activation='relu')(x) #dense layer 2\n",
    "    preds=Dense(4,activation='softmax')(x)\n",
    "    model=Model(inputs=base_model.input,outputs=preds,name=model_name)\n",
    "    model.compile(optimizer='Adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- TRAIN MobileNet ----------------------\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luca\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras_applications\\mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 163 steps, validate for 18 steps\n",
      "Epoch 1/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.1705 - accuracy: 0.9524\n",
      "Epoch 00001: loss improved from inf to 0.16977, saving model to checkpoints/MobileNet/best_model_loss.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18911, saving model to checkpoints/MobileNet/best_model_val_loss.h5\n",
      "163/163 [==============================] - 70s 431ms/step - loss: 0.1697 - accuracy: 0.9527 - val_loss: 0.1891 - val_accuracy: 0.9389\n",
      "Epoch 2/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.1296 - accuracy: 0.9543\n",
      "Epoch 00002: loss improved from 0.16977 to 0.13043, saving model to checkpoints/MobileNet/best_model_loss.h5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.18911\n",
      "163/163 [==============================] - 68s 415ms/step - loss: 0.1311 - accuracy: 0.9540 - val_loss: 0.2308 - val_accuracy: 0.9278\n",
      "Epoch 3/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.1235 - accuracy: 0.9679\n",
      "Epoch 00003: loss improved from 0.13043 to 0.12369, saving model to checkpoints/MobileNet/best_model_loss.h5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.18911\n",
      "163/163 [==============================] - 68s 414ms/step - loss: 0.1236 - accuracy: 0.9675 - val_loss: 0.2711 - val_accuracy: 0.9444\n",
      "Epoch 4/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0912 - accuracy: 0.9728\n",
      "Epoch 00004: loss improved from 0.12369 to 0.09660, saving model to checkpoints/MobileNet/best_model_loss.h5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.18911\n",
      "163/163 [==============================] - 67s 414ms/step - loss: 0.0966 - accuracy: 0.9718 - val_loss: 0.4465 - val_accuracy: 0.8833\n",
      "Epoch 5/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.1701 - accuracy: 0.9555\n",
      "Epoch 00005: loss did not improve from 0.09660\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.18911\n",
      "163/163 [==============================] - 68s 416ms/step - loss: 0.1694 - accuracy: 0.9558 - val_loss: 0.2396 - val_accuracy: 0.9278\n",
      "Epoch 6/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.1363 - accuracy: 0.9586\n",
      "Epoch 00006: loss did not improve from 0.09660\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.18911\n",
      "163/163 [==============================] - 69s 425ms/step - loss: 0.1355 - accuracy: 0.9589 - val_loss: 0.1957 - val_accuracy: 0.9333\n",
      "Epoch 7/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.1099 - accuracy: 0.9648\n",
      "Epoch 00007: loss did not improve from 0.09660\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.18911\n",
      "163/163 [==============================] - 69s 423ms/step - loss: 0.1096 - accuracy: 0.9650 - val_loss: 0.2113 - val_accuracy: 0.9444\n",
      "Epoch 8/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.1254 - accuracy: 0.9660\n",
      "Epoch 00008: loss did not improve from 0.09660\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.18911\n",
      "163/163 [==============================] - 69s 422ms/step - loss: 0.1264 - accuracy: 0.9656 - val_loss: 0.2886 - val_accuracy: 0.9111\n",
      "Epoch 9/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0864 - accuracy: 0.9734\n",
      "Epoch 00009: loss improved from 0.09660 to 0.08735, saving model to checkpoints/MobileNet/best_model_loss.h5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.18911 to 0.16237, saving model to checkpoints/MobileNet/best_model_val_loss.h5\n",
      "163/163 [==============================] - 69s 424ms/step - loss: 0.0873 - accuracy: 0.9730 - val_loss: 0.1624 - val_accuracy: 0.9500\n",
      "Epoch 10/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.1082 - accuracy: 0.9623\n",
      "Epoch 00010: loss did not improve from 0.08735\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.16237\n",
      "163/163 [==============================] - 69s 423ms/step - loss: 0.1076 - accuracy: 0.9626 - val_loss: 0.2215 - val_accuracy: 0.9333\n",
      "Epoch 11/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0931 - accuracy: 0.9679\n",
      "Epoch 00011: loss did not improve from 0.08735\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.16237\n",
      "163/163 [==============================] - 69s 425ms/step - loss: 0.0927 - accuracy: 0.9681 - val_loss: 0.2022 - val_accuracy: 0.9333\n",
      "Epoch 12/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0833 - accuracy: 0.9747\n",
      "Epoch 00012: loss improved from 0.08735 to 0.08289, saving model to checkpoints/MobileNet/best_model_loss.h5\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.16237\n",
      "163/163 [==============================] - 69s 425ms/step - loss: 0.0828 - accuracy: 0.9748 - val_loss: 0.1766 - val_accuracy: 0.9222\n",
      "Epoch 13/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0919 - accuracy: 0.9741\n",
      "Epoch 00013: loss did not improve from 0.08289\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.16237\n",
      "163/163 [==============================] - 69s 424ms/step - loss: 0.0913 - accuracy: 0.9742 - val_loss: 0.3592 - val_accuracy: 0.9389\n",
      "Epoch 14/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0996 - accuracy: 0.9673\n",
      "Epoch 00014: loss did not improve from 0.08289\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.16237\n",
      "163/163 [==============================] - 69s 421ms/step - loss: 0.0993 - accuracy: 0.9675 - val_loss: 0.2098 - val_accuracy: 0.9333\n",
      "Epoch 15/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0757 - accuracy: 0.9741\n",
      "Epoch 00015: loss improved from 0.08289 to 0.07704, saving model to checkpoints/MobileNet/best_model_loss.h5\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.16237 to 0.16044, saving model to checkpoints/MobileNet/best_model_val_loss.h5\n",
      "163/163 [==============================] - 69s 425ms/step - loss: 0.0771 - accuracy: 0.9736 - val_loss: 0.1604 - val_accuracy: 0.9500\n",
      "Epoch 16/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.1059 - accuracy: 0.9728\n",
      "Epoch 00016: loss did not improve from 0.07704\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 69s 421ms/step - loss: 0.1053 - accuracy: 0.9730 - val_loss: 0.4530 - val_accuracy: 0.9389\n",
      "Epoch 17/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.1055 - accuracy: 0.9666\n",
      "Epoch 00017: loss did not improve from 0.07704\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 69s 421ms/step - loss: 0.1049 - accuracy: 0.9669 - val_loss: 0.2630 - val_accuracy: 0.9389\n",
      "Epoch 18/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0598 - accuracy: 0.9839\n",
      "Epoch 00018: loss improved from 0.07704 to 0.05954, saving model to checkpoints/MobileNet/best_model_loss.h5\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 69s 423ms/step - loss: 0.0595 - accuracy: 0.9840 - val_loss: 0.2250 - val_accuracy: 0.9500\n",
      "Epoch 19/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0824 - accuracy: 0.9759\n",
      "Epoch 00019: loss did not improve from 0.05954\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 69s 423ms/step - loss: 0.0819 - accuracy: 0.9761 - val_loss: 0.3759 - val_accuracy: 0.9389\n",
      "Epoch 20/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.1045 - accuracy: 0.9728\n",
      "Epoch 00020: loss did not improve from 0.05954\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 69s 421ms/step - loss: 0.1039 - accuracy: 0.9730 - val_loss: 0.3093 - val_accuracy: 0.9389\n",
      "Epoch 21/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0741 - accuracy: 0.9765\n",
      "Epoch 00021: loss did not improve from 0.05954\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 69s 422ms/step - loss: 0.0737 - accuracy: 0.9767 - val_loss: 0.2015 - val_accuracy: 0.9444\n",
      "Epoch 22/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0498 - accuracy: 0.9846\n",
      "Epoch 00022: loss improved from 0.05954 to 0.04946, saving model to checkpoints/MobileNet/best_model_loss.h5\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 69s 422ms/step - loss: 0.0495 - accuracy: 0.9847 - val_loss: 0.2104 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0593 - accuracy: 0.9809\n",
      "Epoch 00023: loss did not improve from 0.04946\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 69s 422ms/step - loss: 0.0590 - accuracy: 0.9810 - val_loss: 0.1760 - val_accuracy: 0.9167\n",
      "Epoch 24/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0736 - accuracy: 0.9747\n",
      "Epoch 00024: loss did not improve from 0.04946\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 69s 424ms/step - loss: 0.0738 - accuracy: 0.9742 - val_loss: 0.1609 - val_accuracy: 0.9500\n",
      "Epoch 25/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0918 - accuracy: 0.9697\n",
      "Epoch 00025: loss did not improve from 0.04946\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 68s 416ms/step - loss: 0.0915 - accuracy: 0.9699 - val_loss: 0.4163 - val_accuracy: 0.9111\n",
      "Epoch 26/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0979 - accuracy: 0.9716\n",
      "Epoch 00026: loss did not improve from 0.04946\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 412ms/step - loss: 0.0976 - accuracy: 0.9718 - val_loss: 0.2368 - val_accuracy: 0.9222\n",
      "Epoch 27/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0349 - accuracy: 0.9895\n",
      "Epoch 00027: loss improved from 0.04946 to 0.03470, saving model to checkpoints/MobileNet/best_model_loss.h5\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 413ms/step - loss: 0.0347 - accuracy: 0.9896 - val_loss: 0.2241 - val_accuracy: 0.9500\n",
      "Epoch 28/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0243 - accuracy: 0.9901\n",
      "Epoch 00028: loss improved from 0.03470 to 0.02426, saving model to checkpoints/MobileNet/best_model_loss.h5\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 413ms/step - loss: 0.0242 - accuracy: 0.9902 - val_loss: 0.1951 - val_accuracy: 0.9389\n",
      "Epoch 29/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0397 - accuracy: 0.9870\n",
      "Epoch 00029: loss did not improve from 0.02426\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 412ms/step - loss: 0.0395 - accuracy: 0.9871 - val_loss: 0.2217 - val_accuracy: 0.9389\n",
      "Epoch 30/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0385 - accuracy: 0.9883\n",
      "Epoch 00030: loss did not improve from 0.02426\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 412ms/step - loss: 0.0383 - accuracy: 0.9883 - val_loss: 0.2418 - val_accuracy: 0.9389\n",
      "Epoch 31/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0557 - accuracy: 0.9839\n",
      "Epoch 00031: loss did not improve from 0.02426\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 412ms/step - loss: 0.0565 - accuracy: 0.9834 - val_loss: 0.2530 - val_accuracy: 0.9556\n",
      "Epoch 32/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0492 - accuracy: 0.9864\n",
      "Epoch 00032: loss did not improve from 0.02426\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 412ms/step - loss: 0.0490 - accuracy: 0.9865 - val_loss: 0.2668 - val_accuracy: 0.9333\n",
      "Epoch 33/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0457 - accuracy: 0.9846\n",
      "Epoch 00033: loss did not improve from 0.02426\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 412ms/step - loss: 0.0460 - accuracy: 0.9840 - val_loss: 0.3608 - val_accuracy: 0.9389\n",
      "Epoch 34/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9926\n",
      "Epoch 00034: loss did not improve from 0.02426\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 412ms/step - loss: 0.0243 - accuracy: 0.9926 - val_loss: 0.3532 - val_accuracy: 0.9500\n",
      "Epoch 35/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0171 - accuracy: 0.9944\n",
      "Epoch 00035: loss improved from 0.02426 to 0.01720, saving model to checkpoints/MobileNet/best_model_loss.h5\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 414ms/step - loss: 0.0172 - accuracy: 0.9945 - val_loss: 0.3721 - val_accuracy: 0.9500\n",
      "Epoch 36/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9926\n",
      "Epoch 00036: loss did not improve from 0.01720\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 411ms/step - loss: 0.0243 - accuracy: 0.9926 - val_loss: 0.2802 - val_accuracy: 0.9500\n",
      "Epoch 37/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9914\n",
      "Epoch 00037: loss did not improve from 0.01720\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 412ms/step - loss: 0.0283 - accuracy: 0.9914 - val_loss: 0.2621 - val_accuracy: 0.9500\n",
      "Epoch 38/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0168 - accuracy: 0.9938\n",
      "Epoch 00038: loss improved from 0.01720 to 0.01681, saving model to checkpoints/MobileNet/best_model_loss.h5\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 412ms/step - loss: 0.0168 - accuracy: 0.9939 - val_loss: 0.3292 - val_accuracy: 0.9389\n",
      "Epoch 39/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0099 - accuracy: 0.9969\n",
      "Epoch 00039: loss improved from 0.01681 to 0.00992, saving model to checkpoints/MobileNet/best_model_loss.h5\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 413ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.2513 - val_accuracy: 0.9444\n",
      "Epoch 40/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0188 - accuracy: 0.9938\n",
      "Epoch 00040: loss did not improve from 0.00992\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 412ms/step - loss: 0.0187 - accuracy: 0.9939 - val_loss: 0.3430 - val_accuracy: 0.9389\n",
      "Epoch 41/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9951\n",
      "Epoch 00041: loss did not improve from 0.00992\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 412ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.2475 - val_accuracy: 0.9500\n",
      "Epoch 42/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0243 - accuracy: 0.9907\n",
      "Epoch 00042: loss did not improve from 0.00992\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 411ms/step - loss: 0.0241 - accuracy: 0.9908 - val_loss: 0.3487 - val_accuracy: 0.9500\n",
      "Epoch 43/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.9957\n",
      "Epoch 00043: loss did not improve from 0.00992\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 411ms/step - loss: 0.0115 - accuracy: 0.9957 - val_loss: 0.3288 - val_accuracy: 0.9389\n",
      "Epoch 44/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.9951\n",
      "Epoch 00044: loss did not improve from 0.00992\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 411ms/step - loss: 0.0180 - accuracy: 0.9945 - val_loss: 0.2217 - val_accuracy: 0.9389\n",
      "Epoch 45/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0173 - accuracy: 0.9932\n",
      "Epoch 00045: loss did not improve from 0.00992\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 412ms/step - loss: 0.0172 - accuracy: 0.9932 - val_loss: 0.2776 - val_accuracy: 0.9389\n",
      "Epoch 46/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9951\n",
      "Epoch 00046: loss did not improve from 0.00992\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 412ms/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 0.3093 - val_accuracy: 0.9389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.9969\n",
      "Epoch 00047: loss improved from 0.00992 to 0.00971, saving model to checkpoints/MobileNet/best_model_loss.h5\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 413ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.3215 - val_accuracy: 0.9333\n",
      "Epoch 48/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9969\n",
      "Epoch 00048: loss improved from 0.00971 to 0.00783, saving model to checkpoints/MobileNet/best_model_loss.h5\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 412ms/step - loss: 0.0078 - accuracy: 0.9969 - val_loss: 0.2885 - val_accuracy: 0.9389\n",
      "Epoch 49/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9981\n",
      "Epoch 00049: loss improved from 0.00783 to 0.00490, saving model to checkpoints/MobileNet/best_model_loss.h5\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 413ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.2996 - val_accuracy: 0.9389\n",
      "Epoch 50/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0099 - accuracy: 0.9981\n",
      "Epoch 00050: loss did not improve from 0.00490\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 411ms/step - loss: 0.0098 - accuracy: 0.9982 - val_loss: 0.2893 - val_accuracy: 0.9444\n",
      "Epoch 51/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9969\n",
      "Epoch 00051: loss did not improve from 0.00490\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 410ms/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.3508 - val_accuracy: 0.9444\n",
      "Epoch 52/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9963\n",
      "Epoch 00052: loss did not improve from 0.00490\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 411ms/step - loss: 0.0071 - accuracy: 0.9963 - val_loss: 0.3132 - val_accuracy: 0.9444\n",
      "Epoch 53/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9988\n",
      "Epoch 00053: loss did not improve from 0.00490\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 411ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.2804 - val_accuracy: 0.9556\n",
      "Epoch 54/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 00054: loss improved from 0.00490 to 0.00192, saving model to checkpoints/MobileNet/best_model_loss.h5\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 412ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.3189 - val_accuracy: 0.9444\n",
      "Epoch 55/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9994\n",
      "Epoch 00055: loss did not improve from 0.00192\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 411ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.3721 - val_accuracy: 0.9444\n",
      "Epoch 56/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9969\n",
      "Epoch 00056: loss did not improve from 0.00192\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 411ms/step - loss: 0.0144 - accuracy: 0.9969 - val_loss: 0.3609 - val_accuracy: 0.9444\n",
      "Epoch 57/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0094 - accuracy: 0.9981\n",
      "Epoch 00057: loss did not improve from 0.00192\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 410ms/step - loss: 0.0093 - accuracy: 0.9982 - val_loss: 0.3372 - val_accuracy: 0.9444\n",
      "Epoch 58/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9951\n",
      "Epoch 00058: loss did not improve from 0.00192\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 410ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 0.3793 - val_accuracy: 0.9444\n",
      "Epoch 59/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 00059: loss did not improve from 0.00192\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 410ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.3650 - val_accuracy: 0.9444\n",
      "Epoch 60/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9975\n",
      "Epoch 00060: loss did not improve from 0.00192\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 411ms/step - loss: 0.0058 - accuracy: 0.9975 - val_loss: 0.3437 - val_accuracy: 0.9500\n",
      "Epoch 61/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9981\n",
      "Epoch 00061: loss did not improve from 0.00192\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 411ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.3672 - val_accuracy: 0.9500\n",
      "Epoch 62/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9988\n",
      "Epoch 00062: loss did not improve from 0.00192\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 411ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.3512 - val_accuracy: 0.9444\n",
      "Epoch 63/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9969\n",
      "Epoch 00063: loss did not improve from 0.00192\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 410ms/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.3122 - val_accuracy: 0.9500\n",
      "Epoch 64/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9981\n",
      "Epoch 00064: loss did not improve from 0.00192\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 410ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.3186 - val_accuracy: 0.9500\n",
      "Epoch 65/85\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 00065: loss improved from 0.00192 to 0.00170, saving model to checkpoints/MobileNet/best_model_loss.h5\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.16044\n",
      "163/163 [==============================] - 67s 412ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3530 - val_accuracy: 0.9500\n",
      "Epoch 00065: early stopping\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ,'VGG16' 'MobileNet' 'DenseNet201', 'Inception','ResNet',\n",
    "nets = ['MobileNet']\n",
    "num_epochs = 85\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=test_generator.n//test_generator.batch_size\n",
    "\n",
    "histories = []\n",
    "for network in nets:\n",
    "    print('---------------------- TRAIN %s ----------------------'%network)\n",
    "    reduce_lr =  ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.5, patience = 10,verbose = 0, mode = \"auto\", epsilon = 1e-04, cooldown = 0,min_lr = 1e-5)\n",
    "    es = EarlyStopping(monitor = \"val_loss\" , verbose = 1 , mode = 'min' , patience = 50 )\n",
    "    mc = ModelCheckpoint('checkpoints/%s/best_model_loss.h5'%network, monitor = 'loss' , mode = 'min', verbose = 1 , save_best_only = True)\n",
    "    mc_val = ModelCheckpoint('checkpoints/%s/best_model_val_loss.h5'%network, monitor = 'val_loss' , mode = 'min', verbose = 1 , save_best_only = True)\n",
    "    model = get_model(network)\n",
    "    model.load_weights('checkpoints/%s/best_model_val_loss.h5'%network)\n",
    "    history = model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=test_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    callbacks=[reduce_lr,es,mc,mc_val],\n",
    "                    epochs=num_epochs)\n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXxU1fn48c/JzGRPgCxkYQur7IsCAgoo7oqiaBVcUOtSl7q1tdb6a7W11rZ+q7aVuluXooJoFSuKdcUFgQBh3yGQBMi+r5OZ8/vjTCDLZJ9JuMPzfr3ymmTmzp1zIXnuuc95zrlKa40QQgjrC+ruBgghhPANCehCCBEgJKALIUSAkIAuhBABQgK6EEIECHt3fXBcXJxOSUnpro8XQghLWrduXZ7WOt7ba90W0FNSUkhNTe2ujxdCCEtSSh1o7jVJuQghRICQgC6EEAFCAroQQgSIbsuhCyFOTE6nk8zMTKqqqrq7Kce10NBQ+vbti8PhaPN7JKALIbpUZmYmUVFRpKSkoJTq7uYcl7TW5Ofnk5mZycCBA9v8Pkm5CCG6VFVVFbGxsRLMW6CUIjY2tt1XMRLQhRBdToJ56zrybyQBvU7+Xtj7ZXe3QgghOsx6AT1/L6x+ASoKfLvfVQvhPz/x7T6FEMelyMjI7m6CX1gvoB/ZDB/fD6VHfLvf2irzJYQQFmW9gG4LNo+uGt/u11UDrlrf7lMIcVzTWnP//fczevRoxowZw+LFiwE4fPgwM2bMYPz48YwePZpvvvkGl8vFDTfccHTbp556qptb35T1yhZtnppMl9O3+3U5fX+SEEK06HcfbmXboRKf7nNkcjQPXzyqTdu+9957pKWlsXHjRvLy8pg0aRIzZszgzTff5LzzzuOhhx7C5XJRUVFBWloaWVlZbNmyBYCioiKfttsXLNhDrwvovu6hO8HtBLnHqhAnjG+//Zb58+djs9lISEhg5syZrF27lkmTJvGvf/2LRx55hM2bNxMVFcWgQYPYt28fd911F5988gnR0dHd3fwmWu2hK6X6Aa8DiYAbeEFr/bdG2yjgb8CFQAVwg9Z6ve+bi39TLgBuF9isd+EihBW1tSftL7qZDtyMGTNYuXIlH330Eddddx33338/CxYsYOPGjaxYsYKFCxeyZMkSXnnllS5uccva0kOvBX6utR4BTAHuVEqNbLTNBcBQz9etwLM+bWV9dQHd7eN8t9vZ8FEIEfBmzJjB4sWLcblc5ObmsnLlSiZPnsyBAwfo3bs3t9xyCzfddBPr168nLy8Pt9vN5ZdfzqOPPsr69f7ps3ZGq11RrfVh4LDn+1Kl1HagD7Ct3mZzgNe1Od39oJTqqZRK8rzXt/yZcql7dIT5dt9CiOPSZZddxqpVqxg3bhxKKf7yl7+QmJjIa6+9xhNPPIHD4SAyMpLXX3+drKwsbrzxRtxuNwCPP/54N7e+qXblFpRSKcAEYHWjl/oAGfV+zvQ81yCgK6VuxfTg6d+/f/taWsfvKRepdBEi0JWVlQFmNuYTTzzBE0880eD166+/nuuvv77J+47HXnl9bR4UVUpFAu8C92qtGw9Le5uj2iQ5pbV+QWs9UWs9MT7e6x2UWnc0oPu6yqXGP/sVQogu0qaArpRyYIL5Iq31e142yQT61fu5L3Co883zwm8pF0/PXHLoQgiLajWgeypYXga2a62fbGazZcACZUwBiv2SPwcI8ldAlx66EMLa2pJDPw24DtislErzPPdroD+A1vo5YDmmZHEPpmzxRt831cPfKRfJoQshLKotVS7f4j1HXn8bDdzpq0a1qCuqXIQQwoIsOFPUTz10qUMXQlicBQO6v9ZyqcuhS8pFCGFN1gvoQTZQNv+lXKSHLoSop6W109PT0xk9enQXtqZl1gvoYNIufsuhy4qLQghrsuYqVLZg36ZctD7WM5dBUSG6zse/Mjet8aXEMXDBn5p9+YEHHmDAgAHccccdADzyyCMopVi5ciWFhYU4nU7+8Ic/MGfOnHZ9bFVVFbfffjupqanY7XaefPJJzjzzTLZu3cqNN95ITU0Nbrebd999l+TkZK688koyMzNxuVz85je/4aqrrurUYYNlA7rdtz3p+kFcyhaFCGjz5s3j3nvvPRrQlyxZwieffMJ9991HdHQ0eXl5TJkyhUsuuaRdN2peuHAhAJs3b2bHjh2ce+657Nq1i+eee4577rmHa665hpqaGlwuF8uXLyc5OZmPPvoIgOLiYp8cm0UDuo9TLvX3JT10IbpOCz1pf5kwYQI5OTkcOnSI3NxcevXqRVJSEvfddx8rV64kKCiIrKwssrOzSUxMbPN+v/32W+666y4Ahg8fzoABA9i1axdTp07lscceIzMzk7lz5zJ06FDGjBnDL37xCx544AFmz57N9OnTfXJsFs2hO3wbeOsPhMqgqBAB74orrmDp0qUsXryYefPmsWjRInJzc1m3bh1paWkkJCRQVdW+eww3t7b61VdfzbJlywgLC+O8887jiy++YNiwYaxbt44xY8bw4IMP8vvf/94Xh2XhHrovA2/9k4OULQoR8ObNm8ctt9xCXl4eX3/9NUuWLKF37944HA6+/PJLDhw40O59zpgxg0WLFjFr1ix27drFwYMHOemkk9i3bx+DBg3i7rvvZt++fWzatInhw4cTExPDtddeS2RkJK+++qpPjsu6Ad1fKRfpoQsR8EaNGkVpaSl9+vQhKSmJa665hosvvpiJEycyfvx4hg8f3u593nHHHdx2222MGTMGu93Oq6++SkhICIsXL+bf//43DoeDxMREfvvb37J27Vruv/9+goKCcDgcPPusb+4JpJq7TPC3iRMn6tTU1I69+fkZEJUEVy/2TWMK9sPfx5vvL/47nNJ0HWQhhG9s376dESNGdHczLMHbv5VSap3WeqK37S2aQ/d1D11y6EII67NwysWXOfT6VS6SQxdCNLR582auu+66Bs+FhISwenXjm7d1L2sG9CA71LZvBLpFkkMXoktprdtV493dxowZQ1paWusb+lBH0uGScoGGk4mkDl0IvwoNDSU/P79DAetEobUmPz+f0NDQdr3Pmj10f6ZcZKaoEH7Vt29fMjMzyc3N7e6mHNdCQ0Pp27dvu95j0YDu44lFMlNUiC7jcDgYOHBgdzcjIEnKBRoOhMpqi0IIi7JwQJeUixBC1GfRgO6QxbmEEKIRCeggE4uEEAHBogHdxymX+kFceuhCCIuyaED3U8olyCE5dCGEZVk0oHuWz/XVxIS6XnlwuPTQhRCWZdGA7jCPvupNHw3okZJDF0JYlkUDerB59FXapW4/jnBZnEsIYVkS0OFYD90RJj10IYRlWTSge1Iuvsp3u2pA2cAeIjl0IYRlWTOgB9UFdB/10N1Oc5KQKhchhIVZM6D7I+ViCwabXXroQgjLsmhA90PK5WgPXQK6EMKaLBrQ/dVD9/GEJSGE6EIWD+i+6qE7Te88yC5li0IIy7JoQPdTysUmKRchhHVZNKD7YWKRLdj00mVQVAhhURLQwZQq2uyeHrqkXIQQ1mTRgO65FapPUy7Bnhy69NCFENZk0YDup5RL3SqOQghhQRLQwVS21A2KSpWLEMKiWg3oSqlXlFI5Sqktzbx+hlKqWCmV5vn6re+b2Yg/qlzqyhalhy6EsCh7G7Z5FXgGeL2Fbb7RWs/2SYvaoq6H7qvgezTlIlUuQgjrarWHrrVeCRR0QVvazi8zRT1T/7XLd3dCEkKILuSrHPpUpdRGpdTHSqlRzW2klLpVKZWqlErNzc3t+Kf5OuVSt9qir6tnhBCiC/kioK8HBmitxwH/AN5vbkOt9Qta64la64nx8fEd/0R/TiwCyaMLISyp0wFda12itS7zfL8ccCil4jrdspb4ej30upSLr3v+QgjRhTod0JVSiUop5fl+smef+Z3db4t8XuXibNhDl4AuhLCgVqtclFJvAWcAcUqpTOBhwAGgtX4OuAK4XSlVC1QC87T286iiUp51V3zYQw+ql0OXlIsQwoJaDeha6/mtvP4Mpqyxa9mC/XODC5AeuhDCkqw5UxR8WzNevw4dZIEuIYQlWTigB/sm5eJ2m9pzGRQVQlicxQO6DwJvXb68fspFcuhCCAuycED30aBo3T7qp1ykhy6EsCAJ6HXBu8HEIsmhCyGsx8IB3Ucpl7p9BNll6r8QwtIsHND9kHKRHLoQwsIsHNB9dHchrzl0SbkIIazH2gHdJ1UunuBts5u0C0gPXQhhSRYO6FLlIoQQ9Vk4oPtoYpHk0IUQAcK6AT3I7qMql7qUi8wUFUJYm3UDuq976HU3iQYJ6EIIS5KA7i2HLikXIYQFWTig+2i1RVe9tVyO3tpOyhaFENZj4YDuj8W5pGxRCGFdEtClbFEIESAsHNB9vTiXLJ8rhLA2Cwd0Xw2K1lttUab+CyEszMIB3WHuNOR2dW4/9csWlQJlkx66EMKSrB3QofP57vopl7pHyaELISzIwgG9rsSwk2mX+oOiYHrqcoMLIYQFBUBA72Rv2l0vhw5m1UXpoQshLMjCAd1HFSmNUy5BDsmhCyEsycIB3YcplyC7GRAFTw5dUi5CCOsJgIDugx563b7As4qjD8ohhRCii1k4oNdVuXS2h+48NqGobr+SchFCWJB1A3qQrwJ6zbGTA/huSQEhhOhi1g3oPku51DRNuUjZohDCgiwc0H3UQ3fXNuqhy8QiIYQ1WTig+7DKpX5Al7JFIYRFBUBA72R6pHHKRcoWhRAWZeGA7qtB0UYplyC79NCFEJZk4YDuy4lFkkMXQlhfAAR0X1e5yOJcQghrsnBA99z/0xcTixpUucjiXEIIa7JwQPdRysXdeOq/VLkIIawpAAK6L1IujXPoknIRQliPhQO6D9dykSoXIUQAaDWgK6VeUUrlKKW2NPO6Ukr9XSm1Rym1SSl1su+b6UVdD90X66E3qEP30c2nhRCii7Wlh/4qcH4Lr18ADPV83Qo82/lmtYEvl89tUrYoKRchhPW0GtC11iuBghY2mQO8ro0fgJ5KqSRfNbBZQTZQQX6Y+i8pFyGENfkih94HyKj3c6bnuSaUUrcqpVKVUqm5ubmd/2RfpEe8Tv2XgC6EsB5fBHTl5TntbUOt9Qta64la64nx8fGd/+QgHwRfd633skXt9RCEEOK45YuAngn0q/dzX+CQD/bbOpvDRz10e8N9ArhdnduvEEJ0MV8E9GXAAk+1yxSgWGt92Af7bZ0/Ui5BnuAueXQhhMXYW9tAKfUWcAYQp5TKBB4GHABa6+eA5cCFwB6gArjRX41torO3i3O7QLub5tDB7NcR1rn2CSFEF2o1oGut57fyugbu9FmL2qOzA5h17w2q989QV8IoC3QJISzGujNFofMpl7r3Nuih1y36JSkXIYS1WDyg+6iH3rjKBSSHLoSwnAAI6J3oodcF7caLc4H00IUQlmPxgO6rlEujm0SD5NCFEJZj8YDuh5SL9NCFEBZl8YDe2R56SykXWXFRCGEtARDQO9ND9wTtIEm5CCGsz+IBvZO3i/OacpGyRSGENVk8oPtzUFQCuhDCWgIgoHdm6r8MigohAoe1A3qQXcoWhRDCw9oB3S9VLpJDF0JYUwAEdB9UucjUfyFEALB4QO/k1P+jqy16q0OXlIsQwlosHtA9KZeO3i7OW8pFbnAhhLAo6wd06Pjt4rwunytVLkIIa7J4QO/kNH2vZYvBDV8TQgiLsHhA9wTfjgb0oymX+ncsqqtykRy6EMJaLB7QO5keaSnlIj10IYTFBEhA72gPvYWyRVltUQhhMRYP6J1NuXjSKvVvEi1li0IIiwqQgN6JlEuQA5Q69lyQDVCSchFCWI7FA7oPUi710y319ytli0IIi7F4QO9kiaG7tuGkojpBDlmcSwhhORYP6D6ocvEW0G126aELISzH4gG9s4OizaRcgjp5JyQhhOgGlgzoeWXV5pu6YFxb1bEduZzN9NAlhy6EsB7LBfQP0rI49Y+fcyC/HMLjzJPleR3bmcvZQg/dSw69YD88N908CiHEccZyAf3UgbForXl7bQZEJZgnS490bGd1ZYuNNZdDz0yFI5tg1cKOfZ4QQviR5QJ6Yo9QZg1P4J3UTJz2CHBEQFl2x3ZWUwaOsKbP24K959BLD5nHtDehqrhjnymEEH5iuYAOMH9yP/LKqvl8e7bppXe0h16wD2IGNn0+yOF9pmjJYVBB4CyHDYs69plCCOEnlgzoM4fFkxgdyltrMiAysWM99NpqKMqAmMFNX7PZm++hxwyGflNgzfMdX4ddCCH8wJIB3W4L4sqJfVm5O5eKkLiO9dAL9gMaYoc0fS2omSqXksMQnQRTboPCdNj9v/Z/rhBC+IklAzrAlZP6AbCjLLyDAX2veYwd1PS15soWSw9DVDIMnw3RfWD1s+3/XCGE8BPLBvS+vcKZMTSe73McJqddXdq+HeTvMY/eUi5BXlIubrcJ6NFJJuBPugn2fQXZ2zrUfiGE8DXLBnQwg6N7KyPND6XtzKPn7zV17GE9m77mrYdekWdq06OSzc+n3AjBUfDFo+1vuBBC+IGlA/pZIxJwRfQ2P5S1M+2Sv9d7/hy8T/0v8ZQsRieZx/AYmH4f7FwO+1e277OFEMIPLB3QHbYgpo4bBcDhzPT2vblgL8R6SbeAZ2JRo7LF0sPmsa6HDjDlDujRD1Y8ZFIyQgjRjSwd0AHOnzIegPXbdrT9TdVlJkA3F9Db0kMHMynprIfN7NFNb7ej1UII4XttCuhKqfOVUjuVUnuUUr/y8voZSqlipVSa5+u3vm+qd71ie+NUwRzJTKe4oo0LahXsM4/eBkTBew691DOpqC7FU2f05ZB8Mnz+KNRUtK/xQgjhQ60GdKWUDVgIXACMBOYrpUZ62fQbrfV4z9fvfdzOlhqIjuhNL13IO+sy2vaeugqXFnPojVIuJYchMsGkYxpsGwTnPWYmHW1a3L62CyGED7Wlhz4Z2KO13qe1rgHeBub4t1ntE9wziSFhZby2Kh2XW7f+hroa9BgvNejgfXGu0kMQleR9+/5TzZoyebva3GYhhPC1tgT0PkD9rm+m57nGpiqlNiqlPlZKjfK2I6XUrUqpVKVUam5ubgea24yoRAaFlJJRUMnjy7dT5WxlSn7+XjO4GRzu/XVvi3OVHIboZO/bKwW9UszsUSGE6CZtCejKy3ONu8HrgQFa63HAP4D3ve1Ia/2C1nqi1npifHx8+1rakshEIpx5XDmxLy99u5/zn17Jd3taWCM9v4UKF/C+OFdLPXSQgC6E6HZtCeiZQL96P/cFDtXfQGtdorUu83y/HHAopeJ81srWRCWgqor5y5xhvHnzqQBc89JqHv94O1p7ScHk72kS0J0uNwfyy8kuqaJaB6Hr99BrKsxyudFtCOjePk8IIbqAvfVNWAsMVUoNBLKAecDV9TdQSiUC2VprrZSajDlR5Pu6sc2KTDSPZdlMG5LCJ/fO4NH/buP5r/dRUFbD43PHYLd5zl2VhVBZ0GRA9MH3NrN0XSYAP7dncLu9hvySKhKiQ73XoDfWKwWcFVCeC5G9m99OCCH8pNUeuta6FvgpsALYDizRWm9VSt2mlLrNs9kVwBal1Ebg78A87bVr7CdRnoDumf4f6rDxh0tHc+/ZQ3lnXSa3L1p/LK+e37RkcU9OGe+tz2T22CT+eNkYpg5NwI6bB97ZYHr43mrQG+uVYh4l7SKE6CZt6aHXpVGWN3ruuXrfPwM849umtUOk51Z09ab/K6W49+xhxEQE8/Cyrdz02lpeWjCJMC8li3//fDehDhu/u2QUsZEhED4Z9j9PyZ4f+PcPSVwXUddDb2NA7zfZd8cmhBBtZPmZokCTHnp9C6am8NcfjeP7vfnc9NpanLm7zQQhTwDenV3Kh5sOcf20FBPMAYachVY2bojfyWPLt5N/ON3zOS0E9J79zaP00IUQ3SQwAnp4HChbswt0zT25L09eOY4f9uWzdt1a3D36gz0YgKc/3024w8at0+vVpIf1Qg2YxoXBaYQ6bHy3YTM6OBJCo5tvgyPU5NgloAshuklgBPSgIDMQ2cISupeN78OSqRmMrljD98VxPLJsK++tz2T55sPceNpAekUEN3zDsPOw523nyXNjsJcfocgW23o7pHRRCNGNAiOgg0m71FWjNFZ0EBb9iInrH4C4YXzc9y7eXHOQny3ZSGSwnZune7lR9LALAJgVtIHh4WXsKI9kb25Zy22QgC6E6EZtGhS1hMhEKPaylovbBf+6ECoK4Pw/Ez35Fh4LsvFgdS1f7cwhLjKEnuHBTd8XN8RUwuz6hAHBxWytHsxfl25iyU+mEhTkba4VJqBvfAucVSYFI4QQXSiAeugJ3u8tun+lCfSXLjQ3dw6yARAZYmf22GSmDGohlXLSBbB/JbbybIYOGUbqgUJeX5Xe/Pa9UgDt/cQCsPoFsyqjs7KNByVEO+z5DD7vunXxRDt00f0SAquHXpFnFtWyOY49v2WpuVXcsPPbv89h58MqU4150tBhzKyJ50+f7ODzHTn0DA8mPjKE+ZP7MTQhymxfv3QxbmjDfR3eBJ88ANoN2z6Ay56DvhPb3yYhvKmpgA/uMktUDL8I+pzS3S3qHpWFsNFzbwJHuClpHnrO0Y5ch216B/Z/DVPvhN4jvG9TsB++/7tZqdUeaqrpCg9A/m7zmi0YwmPN3c5OXgCTb+lcm7wInIAeVVeLngM9PGuH1VbD9g/NL7gjrP377D8FQnpAdTEqOpk/Xz6WRz/aRlZhJRkFFRwpqeL1VencMC2Fe84eSlSMJxffOI/udsPyX0BYDMx+Clb8Gl4+B2b9P5j+844esRDHrH7WBHNbCPzwHFz+Ytvel7EGkic07ARZVVUJvDEXDq1v+PzMX8GZD3Z8v3u/hP/8BLQLNvwbRs6BGfdD4uhj22SugzevhJpyc59iZ6UJ7D36Qe+RMOJi83NFAVTkm4DvB4ET0I9O/z9yLKDv+dyswTLmio7t0+aAoWfDlnchKpnEHqEsvPrkoy8XlNfwxIqdvPzdfj7YeIi/XD6GMx3h5mzsUVrlJGzL29gzVsOcf8LIS2DQTPjwXnN5nDAahp3X0aMWAsrz4dunzUB+rwGw9mU499Fj8zOas/1DWHwtXPx3OOX6rmmrvzgr4a155u5hVy2ClNPMVctnj8DKv8DgWdD/1PbvN3cXLLke4k+C+W/B+tdN6nTb+zDgdJh0k4kT795iKu1+/EnTq/MuFFg5dGiYR9+y1PSKB53R8f2Om28uk2Kbrp0eExHM43PH8MGdpxEXGcJNr6VSEJyMLtyP1pq31hzk/MeXUfbRr6lOmmT2BRDaw6RcEkbDB3dCWQtLCTdel12Ixr75P6gpg7Mfgcm3mp5g6istv8dZCZ/82nyf/o2/W+hflUWwZAEc+B4uex5GzIawXqZjd9FfTS/5vZtND96bnB3ex98qCkyv2x4MVy82KdWzfgv3boKzfwfFB2Hpjeak2Hs43PxZtwZzCKSAHjMI7GHw9Z9Nr7ymHHZ+bC6POnM5OfQc+OU+8wvSjLF9e/Lu7VM5d2Qi60p6cDh9B1e/uJoH39vMb8OXEqVLue7IlXy/v+DYm+whMPdF80u27K6GqzRqDbs/g9cugT/2gcxUdhwp4Y5F68go8NzmzlnV8WMCU8qZ+i94+xp4/VKzpLCwnsJ0WPMijL/GBJXYweaKL/UVk3JszrdPm4AUOxTSv7PWKqE15eZ398158NQY+PMA2P0pXPx006vx0Gjzd1acCR//sum+trwLz50GT4+BZXebv4PCA/DFY/DsaWYdp3lvHZsJDiYHfvq9cHcaXL0EzngQbvjouFiUT3XlGlr1TZw4Uaempvp2p7s+hbevNgNCE64xgfKGjyDldN9+TjPcbs36F29jxKH/MIXX+evUas754XpKxt3M5fsvJj2vnF9dMJwbpqUcW/1x1T9hxYMw8wEzgJO/F/Z9CTnbzFID7loqgmOZXvgw+VWaqyb248+TyuGNy0xe8LR72t/QFQ8dHeylRz+oLjU36bjydRg4w3f/IML/3r8DtrwHd68/dgOWvV/CG5fCpc/C+KubvqcwHZ6ZbHqy/aea8Z270yDGy3yMttq8FA7+ABf8xUz08zWXE7K3mqvu9W9AVZEpK06eAAmjYMA0M+bVnC8fh6//ZE58Mx8wqal1r8GH95h/g97DYcMic2Obupg45Cw4/b4uix9tpZRap7X2WlERWAEdYOv75jIIZc6Y923t/Ah3e6x+Hj7+Jbk3ryP+/fmmJ33HKkp0CD9bnMZn23MYkRTNo3NGMTElxgyY/vsy2PeVeb89zPyCTroJRl/BtpVLGbnydp5zLCCt/w1s3rGTlT0fxlaRZ47xxo+95wa1hiObISKu4Z2WNr1jLj/HXwun3Q1xw6Bwv+ntFOyFc/8AQ8+F6D5SS3+8qyiAvw6HCdfC7CePPa81/HOKqbKY/7YJXvW9fQ3s/QJ+mmquZp+dasZ3JlxzbJvv/mZ+B1obf3K74cvHTNoH4IpXzI3TO0Jr2PFf+OIPZhnqqCTzVVVkqsRc1WaJjxEXw6k/MYFYNTMnpDFXLXz2sLma0W6TU9+9AoacYzoyweFmpnnqKxBkh3HzoGe/1vfbDU6sgA6Q9ia8fztMu8sEqK60a4XJuw2eZf5orn0XhpwNgNaaj7cc4dH/buNwcRUXjU1i3qR+TOsbjC17M66eKWwpCWd9RjG7c8rYk13GhoxCXg3/G9P0Rg7P+x+Zr9/MeHs6wTd8YEbe3S6yrlpBbHwioQ6buVXeprch7S3I22nudTrnH+aPLGcHvDgLksbB9csapqKqimHpj00tc52IeIjobU4KUUnmBJDg9e6C5nN3fwpJY02vqatlrTeXx4NmQkhU139+d1i10FRM3fZdw4oLML32d28yQXLIWaYE98gm2P+NOYGf9TBM/5kJyE8MNnMuLv2neW/ebnjGEy/GXwMXPgHBEU0/v7LQDO5ve9+U4WWsMcHyjh/a34k6tMFcOR74DuKHm2BdesRU7jgioM/J5qv/tJaXsW5NcRasfAI2vAHDZ5t0jN3LxMLj2IkX0AFytnvy6iH++wxvcnfCQs/yuWPnwdznm2xSUVPLwi/38MaqA5RU1Z3qyLkAABWYSURBVJIYHcrI5GhS0wsoqTK3vusR5mBYQiSjknvws1MjiX75NHMpW1XMA/puHnrwt0Tnb8L90rl85hrPl1GX8JuEVYTv/9SUV/WfanpXm5ZAxmqY/BNzFVBZAD/5xvsfhdtlti1MNznH4kwozzP1/bk7wVUDl/zjWK+tosCUcW37ALI8/5dhveDWr5v2Cv3JWQVPjza9OlswDDjNfH5hOhTsM6msGz7q+t8Ff9IanplkSuRu/sz7NkUZJnCtf90sixHSw1R/DJ4Fp9xoboYOpseevQXu2Wh+/t9v4ftnTC/4h2fNVdyEa6EsG0qyzH4L95vyO5SpqJn6UxPY37kB5r4EY3/UtD3VZeb9MYOOdSYqi0y1V+orpvjgzF/Dydcfa5u/VJWYE39be/jHkRMzoHcXZyU8lmhWgPzpWjOA0owqp4vPt+fw7vpM0vPLmTQghmlDYpkyKJbeUSGo+r9snlRO/qgbOGXduTxw/nAGxkWw4e3f86B9EQAFRFE2Yj79z77t2C32XE7438Pww0JzCb7gg47lyUuz4Z3r4eAqU0lRW2VOFrVVpkc+fLZ5XHoj9BwAN33asdr/jlj/Biz7KZz3uOnR7VphTkQxA005686PTM3/jPv98/nOKvNv6+ueXsZacxJKGN00L53+Lbx6UdNUiTeuWnNyixnovedcN45z3zaTpnxypJn0Nv8t0wl49xYozzHpwOhk6NHX7KvXQHPy7DfJ7MfthudON6mRO1aboJz+nUnH5Oww/zdgJvoNmgmJY2Hti+bEMPknZkwotEdn/9UCngT0rvbZ72DgdNMT8hW3GzLXQJ+JXPuvdWzKLKLS6WJMchRvjVpDaXACP16TzObsSn53ySgWTE1p+P5dn5rgO/KSjrfB5YRP/x+sfs78cY+7ygT3+mmYupTTuKvNJXzBPti02Nx4e8YvfN8j0tpUIygFt33rff9LFpjjv3O1768c3G549ULTa736bUgc0/p7qsvMmj9xw8wAfkhk020y1sIr55oURlgvSJluxlUGnWFeX/pjUwn18x0m/9sZh9LghZmmZx0Saeq5571pJuSBqZapKTftaO3/r662/aInTepm9bNm4D3ldHNTmagkyFxrUnvFGeb4Zz9l0oCiTSSgB5hvd+dx7curGde3B2/cfCrRoebytbLGxd1vb+Cz7dn88+qTuWBMJ3KNLcnZYXpyzV19fPUn+OpxkwvN3XHs+dPvM7XSYALxl4+ZSoN+k00Od8g5x+YTgAmSaW/Cjg9h6l3mBNJYXUXHnIUmLeBNcZZJTwyaaXqdHVWeZ3qQ9cceNr5txjKCPUH58pfhJM8yE26XCciNy2bfvwPSzFUVKsgEs9lPHRt7cFbB8zNMEJ31kOmN7/ncTJqb+lMz/fzpsSbAX/Dnjh9PHbcL/pxixlnKc00u/GfbOlbuq7Vp+5FN5ufJt5r/88Y5eK1NCieit3+qYgKYBPQAo7Xm+735jO3bg6jQhn90VU4XV7/4A1sPlfDmLadyyoDmUz5+43abSprcnTD2ShjzIzMQlfoKnPuYWcPigzth8zum51mwz+RWweR5e/YzASBjDaBNtUVJFlz4f03Xv1j0IzOgdu+WlqtyvvubyQ3Pf9ucPNrj8Eb47u+w9T/myuvqJSYVUl1mBg+jkmDeInhrvtl25BxT55+z3fSer1lqBvQAtv8XFl9jBuwHnmHGLNLehJpSWLAMksebnPI3f20woI6z0gwapr5sTipVxSat0Xt4+46lOYt+BEe2mNTKlDtMXryj0r81i9Cd+WtzEhU+JQH9BFNQXsPcf35HcaWTd2+fxqB4L5f0Xc3tMvn1bR+YtS1ytplZd6f/zLx+ZJNZGbPooPkqzzPVGeOvMYOa79wAuz4+Vp0BZlr2wklmYscZv2r5811Ok98tzjJXAe5aCImG8/5ognRjziqTe1//uskjB0fBsHPNRJRRc01P/Ks/mhPVjz81paM15WZyyv6vzdVJ4hhThldVbIJ1dB9TThidDDd/fiznXnjA5MOrS+G8x8w+xs03K4Q2tuMjczJMHGsqlXzl26fMNHmAO9dC/DDf7Vv4lAT0E1B6Xjlzn/2eKqeL22YO5ubpAwkPblg5oLXmq525pGUUcc7IBEYlRzcYiK2pdRNs9+HlcG01LLoCDqwy+fWxV7b9vS4n/Oc2M7Ekfrg5KZRlQ2aqmWsQGd/6PrK3mhmS2mXqmbNSzbo7M38JM34JaDMNftsHsOU/UF1s8r+TbjJVIWE9j/X0x15lths+G654ufnPLDwAr86G6hLT5qx18JOvm67YV7DfbFeSaQZy7/yh+dnJ1WUml+2tlLCjMtbCy2dDv1PNgLY4bklAP0EdzK/g8Y+38/GWIyREh7BgagqjkqMZlhBFen45f/10F+sOFB7dflhCJDOGxnOgoIJth0rIKqokIthGQnQoCdGhjO3bg1MG9GJiSgwxjW/Z11Yup+l9d6SW2O2CH/5pLulztpme/MSbGk6qaY/qMlh+P2x8E+JHmCqMqmKz7OqIS8wsy5TpDXO8WpuB4VXPmIHhu1JN1UdL6oJ68UGTcpr2U+/bFewzvfPpP/PtgHpbuJxmqYnT7m5/Skp0KQnoJ7jU9AL+uHw76w8WNXg+qUcod80ayjkjE1ix9Qjvrc9kQ0YRA2MjGJkczeD4SEqraskurSKrsJJth0qocZmF+oclRDJtcBxTBsVy+tA4IkPaVjecX1ZNRY2LfjGdrMwAs5qePbTzg2obF5ued9I4Mx1+8KyWSy7rZkfGDfM+UOtNcaap7JiwQAYBRadIQBcAFJbXsCu7lF05ZTiCFJdO6GNml9bjcmtszdxir8rpYktWMav3F/DDvnzWphdQ5XQTYg/irBG9uWRcH6YOiiU6zN4gdeNya1bvz+fN1QdZsfUItW7N/eedxO0zBx/dLi2jiE+3HuGyCX2O3TBECNGEBHThFzW1btYfLGT55sN8tOkw+eU1AEQE20juGYYtSJFXVkNBeTVubWa/zj25Dzml1Xy06TAXjU3iwQuG88wXe1icmoHWYAtSzJ/cj/vOHkZsZPtndlbWuFiSam4BuGDqgAYnFq01pdW1R8s8hbAiCejC72pdblbty2fnkVKyiirJKqzErTVxkSHERYYwNCGS80aZ9Wa01jz39T7+smIHWoM9SHHjaSksmJrCS9/s49+rDxLmsHHm8N7MHBbPjKFx9I5uviRRa01RhZN31mXwwsp95JWZE8vck/vwp7ljCbYHcaiokp8v2cja9ALmTe7H3bOGtrhPIY5XEtDFcenrXbl8sCGL284YzLB6aZY9OWU8+9Vevt6VS16ZWdM7uUcoI5KiOSkxCpdbc6SkiuySKrJLqjlSXEWl0wXA6UPiuGvWEFbvL+DJ/+1i6qBY5p7ch0f/u41at+asEQl8vPkwdpvi+mkp3DhtIIk9GgZ2l1uTllHEFzuyWbu/kFkjenPz6QOPLXmMSREpYGzfHg2XaMCcYFbty+e179PZeqiEYQlRjEyKZly/npx5UnyD/QjRXhLQhSW53ZrtR0r4bk8eWw+VsO1QCfvyyrEpRUKPEBKiQknoEUpitPmamNKLCf2Plfr9Z0Mmv1y6CadLM75fT56+ajwpcREcyC/nqf/t4oONhwhSinNHJjBnfDIHCypYm17I2vQCiiqc2IIUKbHh7M0tZ1y/nvz1R2Mprqzlyf/t5Ls9+QAMiA1nzrhkhiVGkV1STXZJFV/vzGVndim9wh1MGRTLvtxy9uSW4XJr+sWEcev0QfxoYr8m4xdCtIUEdBEwnC439iDVpFfcnHUHCtiSVcLVp/bH0ahnfDC/gkVrDrBkbQaFFeZWfymx4UxMiWHGsHhmDo0nOszOh5sO8/AHWyitqqXWrYmLDOa2mYOJDnOwLO0Q3+/Nw+35MwqxBzE8KZprTu3PJeOSjwbtKqeLlbtyefbrvWw4WESvcAfTBscxMaUXk1JiGJkUTVAzg9FC1CcBXYgWVDldpGUUMTg+kvgo7wOxuaXVLPxyDwnRoSyYOoCIemWauaXV5JdXkxgdSo8wR4snG601a/YX8PbaDNbsLyCrqBKA+KgQzh7Rm3NGJnDGsN4S3EWzJKALcZw6VFTJD/vy+Xx7Dl/vyqWsupYFUwfw+zmjW3+zOCG1FND9vIq8EKIlyT3DmHtyX+ae3JfqWhePL9/Bq9+nc3L/Xlw6oU93N09YjAy3C3GcCLHbeOiiEUxOieHB9zaz80hpm9+rtSazsII9OaV011W36H6SchHiOJNTUsVF//iWyBA7j106mooaF+U1tfQMD2ZwfATJPcKornWzMbOIdQcK2XCwiLSMoqMlnkN6RzJnXDKzRvQmOtRBiCOIMIeNyBB7mweTxfFLcuhCWMya/QXMf/EHXO6mf5+hjiBqXZpaz2uD4iIY368n4/v3RAEfbjzMmvSCJu9z2BQxEcHERIQQFWonOtROdKiDpJ6h9O0VTt9eYYzv17PJGvvi+CIBXQgL2ptbRnZxFZGhdsKD7RSU17A3t4y9OWWEOII4ZUAvJvTrRS8vK19mFVWy7kAhVU4X1bVuKmtqKSh3UlBeTUG5k5IqJ2VVtRRXOskuqTp6cgi2BTF9aBznj05k5knx9I46Nukqo6CC9zdkkVNazYDYcAbERpDUI5SIEDsRITZC7GYWsMutsduC6BEmJwZ/kEFRISxocHwkgxvdnGTywLbdgapPzzD69GzbTbprXW6yS6vZn1vOFztyWLH1CJ/vyAFgYFwEk1J6cSC/gtX7C1AKIkPslFbVtrrfnuEOBsZF0D8mnMgQO6EOG3ab4nBRFQcKKjhUVElcZAiD4iMYHB/JOSMSGNPXWjeJ/mJHNh+kHWJEUjSnDoxhdJ8eTeY7dCXpoQshGtBasyWrhFX78lizv4DUA4XEhAcz9+Q+XHZyX/r0DKOooob0/AqyS6oor66lvLqW6lo3QUphC1JU17o4kF/B/rxyMgorqKxxUVnjwunS9I4OYUBsOMk9wsgrq2ZvbjmZhRW4NUxOieGm6QMZ368nFTUuKmpq0dpM2HLYgsgtq2b9gULWHyykvNrFrOG9OW90YpOTV5XTxZ6cMg4WVBATEUyfnmEkRIdSWFFDZmElR4qriI0MZmjvyA4tAldc6eTR/25j6bpMokKPneCiQuzcfuZgbjp9ICF27zOBq5wunC53h1NbnU65KKXOB/4G2ICXtNZ/avS68rx+IVAB3KC1Xt/SPiWgCyHqlFQ5WbI2g399l350slVL+seEE2IPYndOGWCuJEI8d9eqcro4WFCBl+EHr2IighkSH8ng3uZKoXd0KOEOG2HBNpQyq4pW17opq6olp7SanNIqPt58hNyyam6fOZi7zhpCSWUta/YX8J8NWXy2PZsBseE8eMEIpg2JJcozCW1zVjFLUjNYlnaIm04fxD1nD+3Qv1WnArpSygbsAs4BMoG1wHyt9bZ621wI3IUJ6KcCf9Nan9rSfiWgCyEaq3W5+WJHDrll1YQH2whz2FBKUVPrPtqrndC/J3GeXvX+vHJWbD1C2sEi3J5Y5rAFMTg+gpMSoxkQG05hRQ2Hiio5UlxNTISDPr3CSIw2Vwe7c8rYk1PKnpwy9uaWU+BZArolkSF2hiZE8sjFoxjXr2eT17/ZncvvPtzGHs/JJsxhIzLUTm5pNSH2IM4fnch1UwYwMaVjN3DvbECfCjyitT7P8/ODAFrrx+tt8zzwldb6Lc/PO4EztNaHm9uvBHQhxPGmoNys31/hSRG5tCbEbiPEHkRkiJ34qJAGyz40x+ly8/n2bDIKKskuqSK/vIaJKb2YPTa504PFnR0U7QNk1Ps5E9MLb22bPkCzAV0IIY43pqyzg/fLrcdhC+L80R24b24ntWU41ttMhMbd+rZsg1LqVqVUqlIqNTc3ty3tE0II0UZtCeiZQL96P/cFDnVgG7TWL2itJ2qtJ8bHx7e3rUIIIVrQloC+FhiqlBqolAoG5gHLGm2zDFigjClAcUv5cyGEEL7Xag5da12rlPopsAJTtviK1nqrUuo2z+vPAcsxFS57MGWLN/qvyUIIIbxp00xRrfVyTNCu/9xz9b7XwJ2+bZoQQoj2kOVzhRAiQEhAF0KIACEBXQghAkS3Lc6llMoFDnTw7XFAng+bYyUn6rHLcZ9Y5LibN0Br7bXuu9sCemcopVKbm/oa6E7UY5fjPrHIcXeMpFyEECJASEAXQogAYdWA/kJ3N6AbnajHLsd9YpHj7gBL5tCFEEI0ZdUeuhBCiEYkoAshRICwXEBXSp2vlNqplNqjlPpVd7fHX5RS/ZRSXyqltiultiql7vE8H6OU+p9SarfnsVd3t9UflFI2pdQGpdR/PT8H/HErpXoqpZYqpXZ4/t+nniDHfZ/nd3yLUuotpVRooB63UuoVpVSOUmpLveeaPVal1IOeWLdTKXVea/u3VED33N90IXABMBKYr5Qa2b2t8pta4Oda6xHAFOBOz7H+Cvhcaz0U+NzzcyC6B9he7+cT4bj/BnyitR4OjMMcf0Aft1KqD3A3MFFrPRqzous8Ave4XwXOb/Sc12P1/L3PA0Z53vNPTwxslqUCOjAZ2KO13qe1rgHeBuZ0c5v8Qmt9WGu93vN9KeaPuw/meF/zbPYacGn3tNB/lFJ9gYuAl+o9HdDHrZSKBmYALwNorWu01kUE+HF72IEwpZQdCMfcHCcgj1trvRIoaPR0c8c6B3hba12ttd6PWZ58ckv7t1pAb+7epQFNKZUCTABWAwl1Nw/xPPbuvpb5zdPALwF3vecC/bgHAbnAvzypppeUUhEE+HFrrbOA/wMOYu5BXKy1/pQAP+5GmjvWdsc7qwX0Nt27NJAopSKBd4F7tdYl3d0ef1NKzQZytNbrurstXcwOnAw8q7WeAJQTOGmGZnnyxXOAgUAyEKGUurZ7W3XcaHe8s1pAb9O9SwOFUsqBCeaLtNbveZ7OVkoleV5PAnK6q31+chpwiVIqHZNSm6WU+jeBf9yZQKbWerXn56WYAB/ox302sF9rnau1dgLvAdMI/OOur7ljbXe8s1pAb8v9TQOCUkph8qnbtdZP1ntpGXC95/vrgQ+6um3+pLV+UGvdV2udgvn//UJrfS2Bf9xHgAyl1Emep84CthHgx41JtUxRSoV7fufPwowXBfpx19fcsS4D5imlQpRSA4GhwJoW96S1ttQX5t6lu4C9wEPd3R4/HufpmMurTUCa5+tCIBYzEr7b8xjT3W3147/BGcB/Pd8H/HED44FUz//5+0CvE+S4fwfsALYAbwAhgXrcwFuYsQInpgd+U0vHCjzkiXU7gQta279M/RdCiABhtZSLEEKIZkhAF0KIACEBXQghAoQEdCGECBAS0IUQIkBIQBdCiAAhAV0IIQLE/wfmYKo4rqTHYAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for history in histories:\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    plt.plot(loss,label='loss')\n",
    "    plt.plot(val_loss,label='val_loss')\n",
    "    plt.legend()\n",
    "    #plt.savefig('loss.png')\n",
    "    plt.show()\n",
    "\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    plt.plot(acc,label='acc')\n",
    "    plt.plot(val_acc,label='val_acc')\n",
    "    plt.legend()\n",
    "    #plt.savefig('acc.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 409 steps, validate for 45 steps\n",
      "Epoch 1/25\n",
      "408/409 [============================>.] - ETA: 0s - loss: 1.3032 - accuracy: 0.3219\n",
      "Epoch 00001: loss improved from inf to 1.30310, saving model to checkpoints/Inception/best_model_loss.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5.42784, saving model to checkpoints/Inception/best_model_val_loss.h5\n",
      "409/409 [==============================] - 78s 191ms/step - loss: 1.3030 - accuracy: 0.3217 - val_loss: 5.4278 - val_accuracy: 0.3389\n",
      "Epoch 2/25\n",
      "408/409 [============================>.] - ETA: 0s - loss: 1.2642 - accuracy: 0.3164\n",
      "Epoch 00002: loss improved from 1.30310 to 1.26401, saving model to checkpoints/Inception/best_model_loss.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 5.42784 to 1.27709, saving model to checkpoints/Inception/best_model_val_loss.h5\n",
      "409/409 [==============================] - 71s 173ms/step - loss: 1.2640 - accuracy: 0.3162 - val_loss: 1.2771 - val_accuracy: 0.3278\n",
      "Epoch 3/25\n",
      "408/409 [============================>.] - ETA: 0s - loss: 1.2557 - accuracy: 0.3115\n",
      "Epoch 00003: loss improved from 1.26401 to 1.25578, saving model to checkpoints/Inception/best_model_loss.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.27709 to 1.26955, saving model to checkpoints/Inception/best_model_val_loss.h5\n",
      "409/409 [==============================] - 71s 173ms/step - loss: 1.2557 - accuracy: 0.3113 - val_loss: 1.2695 - val_accuracy: 0.3333\n",
      "Epoch 4/25\n",
      "303/409 [=====================>........] - ETA: 16s - loss: 1.2538 - accuracy: 0.2991WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "\n",
      "Epoch 00004: loss improved from 1.25578 to 1.25282, saving model to checkpoints/Inception/best_model_loss.h5\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "303/409 [=====================>........] - ETA: 17s - loss: 1.2538 - accuracy: 0.2991"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-e8d84bba48b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSTEP_SIZE_VALID\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmc_val\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                     epochs=25)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1304\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1305\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=test_generator.n//test_generator.batch_size\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=test_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    callbacks=[reduce_lr,es,mc,mc_val],\n",
    "                    epochs=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
